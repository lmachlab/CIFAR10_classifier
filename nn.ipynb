{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmachlab/CIFAR10_classifier/blob/master/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg23YThjpfGY"
      },
      "source": [
        "# Load PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JiNjAFBcpfGZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CIFAR-10 dataset\n"
      ],
      "metadata": {
        "id": "-qFnsjoA-5sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "valid_ratio = 0.02\n",
        "\n",
        "#load train data and create a train and valid dataset\n",
        "train_data = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "n_train_examples = int((1-valid_ratio) * len(train_data))\n",
        "n_valid_examples = int(valid_ratio * len(train_data))\n",
        "train_set, valid_set = torch.utils.data.random_split(train_data, [n_train_examples, n_valid_examples])\n",
        "\n",
        "\n",
        "#load test set\n",
        "test_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t10Eg_1j_C8a",
        "outputId": "70cfbde0-f45e-47dc-8e8c-c7dfeb53c58c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model structure\n"
      ],
      "metadata": {
        "id": "Lrhh0y389e8e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "63Ku2cfkpfGZ"
      },
      "outputs": [],
      "source": [
        "class NNetwork1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 convolutional layer\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(6*16*16, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class NNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 2 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(6, 12, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(12*8*8, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class NNetwork3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 3 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(6, 12, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(12, 24, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(24*4*4, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class NNetwork4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 4 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(6, 12, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(12, 24, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(24, 48, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(48*2*2, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class NNetwork5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 5 convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv2 = nn.Conv2d(6, 12, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(12, 24, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(24, 48, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(48, 96, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.fc1 = nn.Linear(96*1*1, 10)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "        x = torch.flatten(x, 1) \n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run model"
      ],
      "metadata": {
        "id": "xoaZkCcLW7Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def run_model(model,running_mode='train', train_set=None, valid_set=None, test_set=None,\n",
        "    batch_size=1, learning_rate=0.01, n_epochs=1, stop_thr=1e-4, shuffle=True):\n",
        "   \n",
        "\n",
        "    if running_mode == 'train':\n",
        "      trainsets = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
        "      if valid_set != None:\n",
        "        validsets = DataLoader(valid_set, batch_size=batch_size, shuffle=shuffle)\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "      loss_dict = {'train':[], 'valid':[]}\n",
        "      acc_dict = {'train':[], 'valid':[]}\n",
        "      epoch_index = 0\n",
        "      for epoch in range(n_epochs):\n",
        "        model, train_loss, train_accuracy = _train(model=model, data_loader=trainsets, optimizer=optimizer)\n",
        "        loss_dict['train'].append(train_loss)\n",
        "        acc_dict['train'].append(train_accuracy)\n",
        "        if valid_set != None:\n",
        "          valid_loss, valid_accuracy = _test(model=model, data_loader=validsets)\n",
        "          loss_dict['valid'].append(valid_loss)\n",
        "          acc_dict['valid'].append(valid_accuracy)\n",
        "          if epoch_index > 1:\n",
        "            loss_diff = loss_dict['valid'][-1] - loss_dict['valid'][-2]\n",
        "            if abs(loss_diff) < stop_thr:\n",
        "              return model, loss_dict, acc_dict\n",
        "        epoch_index += 1\n",
        "      return model, loss_dict, acc_dict\n",
        "    else:\n",
        "      testsets = DataLoader(test_set, batch_size=batch_size, shuffle=shuffle)\n",
        "      test_loss, test_accuracy = _test(model=model, data_loader=testsets)\n",
        "      return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "def _train(model,data_loader,optimizer,device=torch.device('cpu')):\n",
        "\n",
        "  \n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    total_data = 0\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "    correct_assign = 0\n",
        "    for data in data_loader:\n",
        "      X, y = data\n",
        "      optimizer.zero_grad()\n",
        "      output = model(X.float())\n",
        "      y = y.type(torch.LongTensor)\n",
        "      loss_value = loss(output, y)\n",
        "      loss_value.backward()\n",
        "      optimizer.step()\n",
        "      total_data += 1\n",
        "      total_loss += loss_value.item()\n",
        "      total_examples += len(y)\n",
        "      predictions = torch.argmax(output, dim=1)\n",
        "      correct_assign += torch.sum(predictions == y)\n",
        "\n",
        "    train_accuracy = correct_assign / total_examples\n",
        "    train_accuracy *= 100\n",
        "    train_loss = total_loss / total_data\n",
        "    return model, train_loss, train_accuracy\n",
        "\n",
        "\n",
        "def _test(model, data_loader, device=torch.device('cpu')):\n",
        "    \n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    total_data = 0\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "    correct_assign = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "      X, y = data\n",
        "      output = model(X.float())\n",
        "      y = y.type(torch.LongTensor)\n",
        "      loss_value = loss(output, y)\n",
        "      total_data += 1\n",
        "      total_loss += loss_value.item()\n",
        "      total_examples += len(data[0])\n",
        "      predictions = torch.argmax(output, dim=1)\n",
        "      correct_assign += torch.sum(predictions == y)\n",
        "    \n",
        "    test_accuracy = correct_assign / total_examples\n",
        "    test_accuracy *= 100\n",
        "    test_loss = total_loss / total_data\n",
        "    return test_loss, test_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "Iy3uoIIIUw-Z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "2dh90PdIYSkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the five neural networks (varying in number of convolutional layers) for 15 epochs each"
      ],
      "metadata": {
        "id": "TVIREKrKchad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NNetwork1()\n",
        "model2 = NNetwork2()\n",
        "model3 = NNetwork3()\n",
        "model4 = NNetwork4()\n",
        "model5 = NNetwork5()\n",
        "\n",
        "trained_model_1, loss_dict_1, acc_dict_1 = run_model(model1, running_mode='train', train_set=train_set, valid_set=valid_set, batch_size=10, n_epochs=15, shuffle=True)\n",
        "trained_model_2, loss_dict_2, acc_dict_2 = run_model(model2, running_mode='train', train_set=train_set, valid_set=valid_set, batch_size=10, n_epochs=15, shuffle=True)\n",
        "trained_model_3, loss_dict_3, acc_dict_3 = run_model(model3, running_mode='train', train_set=train_set, valid_set=valid_set, batch_size=10, n_epochs=15, shuffle=True)\n",
        "trained_model_4, loss_dict_4, acc_dict_4 = run_model(model4, running_mode='train', train_set=train_set, valid_set=valid_set, batch_size=10, n_epochs=15, shuffle=True)\n",
        "trained_model_5, loss_dict_5, acc_dict_5 = run_model(model5, running_mode='train', train_set=train_set, valid_set=valid_set, batch_size=10, n_epochs=15, shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9RgcaXADYW33"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "Bw3J8k_pbsoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test each model trained, and record the accuracy of each"
      ],
      "metadata": {
        "id": "ewc8nYP7dDC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_1, test_accuracy_1 = run_model(trained_model_1, running_mode='test', test_set=test_set, batch_size=10, shuffle=False)\n",
        "print(\"percentage of accurately labeled images with one convolutional layer: \", test_accuracy_1)\n",
        "\n",
        "test_loss_2, test_accuracy_2 = run_model(trained_model_2, running_mode='test', test_set=test_set, batch_size=10, shuffle=False)\n",
        "print(\"percentage of accurately labeled images with two convolutional layers: \", test_accuracy_2)\n",
        "\n",
        "test_loss_3, test_accuracy_3 = run_model(trained_model_3, running_mode='test', test_set=test_set, batch_size=10, shuffle=False)\n",
        "print(\"percentage of accurately labeled images with three convolutional layers: \", test_accuracy_3)\n",
        "\n",
        "test_loss_4, test_accuracy_4 = run_model(trained_model_4, running_mode='test', test_set=test_set, batch_size=10, shuffle=False)\n",
        "print(\"percentage of accurately labeled images with four convolutional layers: \", test_accuracy_4)\n",
        "\n",
        "test_loss_5, test_accuracy_5 = run_model(trained_model_5, running_mode='test', test_set=test_set, batch_size=10, shuffle=False)\n",
        "print(\"percentage of accurately labeled images with five convolutional layers: \", test_accuracy_5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFFhzJKmbuNb",
        "outputId": "0e0308a6-88d1-48aa-e30c-839e38abb703"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "percentage of accurately labeled images with one convolutional layer:  tensor(54.7500)\n",
            "percentage of accurately labeled images with two convolutional layers:  tensor(59.8200)\n",
            "percentage of accurately labeled images with three convolutional layers:  tensor(62.3800)\n",
            "percentage of accurately labeled images with four convolutional layers:  tensor(61.8900)\n",
            "percentage of accurately labeled images with five convolutional layers:  tensor(64.5100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3PkuUMbEcKGY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}